h_total = h_total+1
h_price_sum = h_price_sum + ifelse(is.na(ld_train$Price[i]),0,ld_train$Price[i])
}
if(ld_train$Type[i] == 't'){
t_total = t_total+1
t_price_sum = t_price_sum + ifelse(is.na(ld_train$Price[i]),0,ld_train$Price[i])
}
}
h_price_sum
h_total
t_price_sum
h_total
avg_h = h_price_sum/h_total
avg_t = t_price_sum/h_total
diff = avg_h- avg_t
avg_h
avg_t
diff
}
library(dplyr)
library(visdat)
library(tidyr)
library(car)
library(stringr)
library(pROC)
setwd("C:\\Users\\Admin\\Desktop\\retail")
ld_train = read.csv("store_train.csv",stringsAsFactors = F)
ld_test  =read.csv("store_test.csv",stringsAsFactors = F)
ld_test$store=NA
ld_train$data = "train"
ld_test$data = "test"
ld_all = rbind(ld_train,ld_test)
sales_vector = c("sales0","sales1","sales2","sales3","sales4")
for(i in sales_vector){
print(sum(is.na(ld_all[,i])))
}
ld_all$sales_mean = rowMeans(subset(ld_all, select = c("sales0","sales1","sales2","sales3","sales4")), na.rm = TRUE)
ld_all = ld_all %>%
select(-sales_vector)
table(ld_all$store_Type)
CreateDummies=function(data,var,freq_cutoff=0){
t=table(data[,var])
t=t[t>freq_cutoff]
t=sort(t)
categories=names(t)[-1]
for( cat in categories){
name=paste(var,cat,sep="_")
name=gsub(" ","",name)
name=gsub("-","_",name)
name=gsub("\\?","Q",name)
name=gsub("<","LT_",name)
name=gsub("\\+","",name)
name=gsub("\\/","_",name)
name=gsub(">","GT_",name)
name=gsub("=","EQ_",name)
name=gsub(",","",name)
data[,name]=as.numeric(data[,var]==cat)
}
data[,var]=NULL
return(data)
}
ld_all = CreateDummies(ld_all,"store_Type",10)
ld_all$storecode = substr(ld_all$storecode, start = 1, stop = 5)
ld_all = CreateDummies(ld_all,"storecode",50)
ld_all$Id=NULL
ld_all$State=NULL
ld_all$countyname=NULL
ld_all$countytownname=NULL
ld_all$country=NULL
ld_all$Areaname=NULL
ld_all=CreateDummies(ld_all,"state_alpha",0)
#vis_dat(ld_all)
lgr_train=ld_all %>% filter(data=='train') %>% select(-data)
lgr_test=ld_all %>% filter(data=='test') %>% select (-data,-store)
set.seed(2)
s=sample(1:nrow(lgr_train),0.8*nrow(lgr_train))
lgr_train1=lgr_train[s,] ## 80% Train data
lgr_train2=lgr_train[-s,] ## 20% Train Test Data
for_vif=lm(store~.-state_alpha_GU,data = lgr_train1)
sort(vif(for_vif), decreasing = T)[1:3]
log_fit = glm(store~.-state_alpha_GU,data = lgr_train1)
log_fit = step(log_fit)
formula(log_fit)
log_fit= glm(store~ storecode_NCNTY + state_alpha_HI + state_alpha_NC,data = lgr_train1, family ='binomial')
summary(log_fit)
val.score=predict(log_fit,newdata = lgr_train2, type='response')
val.score[,1]
val.score
auc(roc(lgr_train2$store,val.score))
val.score[,1]
val.score[1]
val.score[,1]
auc(roc(lgr_train2$store,val.score))
log_fit_final= glm(store~ storecode_NCNTY + state_alpha_HI + state_alpha_NC,data = lgr_train, family ='binomial')
summary(log_fit_final)
test_prob_score = predict(log_fit_final, newdata = lgr_test, type='response',row.names= F )
test_prob_score
auc(roc(lgr_test,test_prob_score))
auc(roc(lgr_test$store,test_prob_score))
val.score[,1]
val.score
auc(roc(lgr_train2$store,val.score))
log_fit_final= glm(store~ storecode_NCNTY + state_alpha_HI + state_alpha_NC,data = lgr_train, family ='binomial')
summary(log_fit_final)
test_prob_score = predict(log_fit_final, newdata = lgr_test, type='response',row.names= F )
test_prob_score
auc(roc(lgr_test$store,test_prob_score))
auc(roc(lgr_test$store_Type_SupermarketType3,test_prob_score))
library(dplyr)
library(visdat)
library(tidyr)
library(car)
library(stringr)
library(pROC)
setwd("C:\\Users\\Admin\\Desktop\\retail")
ld_train = read.csv("store_train.csv",stringsAsFactors = F)
ld_test  =read.csv("store_test.csv",stringsAsFactors = F)
ld_test$store=NA
ld_train$data = "train"
ld_test$data = "test"
ld_all = rbind(ld_train,ld_test)
sales_vector = c("sales0","sales1","sales2","sales3","sales4")
for(i in sales_vector){
print(sum(is.na(ld_all[,i])))
}
ld_all$sales_mean = rowMeans(subset(ld_all, select = c("sales0","sales1","sales2","sales3","sales4")), na.rm = TRUE)
ld_all = ld_all %>%
select(-sales_vector)
table(ld_all$store_Type)
CreateDummies=function(data,var,freq_cutoff=0){
t=table(data[,var])
t=t[t>freq_cutoff]
t=sort(t)
categories=names(t)[-1]
for( cat in categories){
name=paste(var,cat,sep="_")
name=gsub(" ","",name)
name=gsub("-","_",name)
name=gsub("\\?","Q",name)
name=gsub("<","LT_",name)
name=gsub("\\+","",name)
name=gsub("\\/","_",name)
name=gsub(">","GT_",name)
name=gsub("=","EQ_",name)
name=gsub(",","",name)
data[,name]=as.numeric(data[,var]==cat)
}
data[,var]=NULL
return(data)
}
ld_all = CreateDummies(ld_all,"store_Type",10)
ld_all$storecode = substr(ld_all$storecode, start = 1, stop = 5)
ld_all = CreateDummies(ld_all,"storecode",50)
ld_all$Id=NULL
ld_all$State=NULL
ld_all$countyname=NULL
ld_all$countytownname=NULL
ld_all$country=NULL
ld_all$Areaname=NULL
ld_all=CreateDummies(ld_all,"state_alpha",0)
#vis_dat(ld_all)
lgr_final_test = lgr_test=ld_all %>% filter(data=='test')
lgr_train=ld_all %>% filter(data=='train') %>% select(-data)
lgr_test=ld_all %>% filter(data=='test') %>% select (-data,-store)
set.seed(2)
s=sample(1:nrow(lgr_train),0.8*nrow(lgr_train))
lgr_train1=lgr_train[s,] ## 80% Train data
lgr_train2=lgr_train[-s,] ## 20% Train Test Data
for_vif=lm(store~.-state_alpha_GU,data = lgr_train1)
sort(vif(for_vif), decreasing = T)[1:3]
log_fit = glm(store~.-state_alpha_GU,data = lgr_train1)
log_fit = step(log_fit)
formula(log_fit)
log_fit= glm(store~ storecode_NCNTY + state_alpha_HI + state_alpha_NC,data = lgr_train1, family ='binomial')
summary(log_fit)
val.score=predict(log_fit,newdata = lgr_train2, type='response')
val.score
auc(roc(lgr_train2$store,val.score))
log_fit_final= glm(store~ storecode_NCNTY + state_alpha_HI + state_alpha_NC,data = lgr_train, family ='binomial')
summary(log_fit_final)
test_prob_score = predict(log_fit_final, newdata = lgr_test, type='response',row.names= F )
test_prob_score
#vis_dat(ld_all)
lgr_final_test = lgr_test=ld_all %>% filter(data=='test') %>% select(-data)
auc(roc(lgr_final_test$store,test_prob_score))
auc(roc(log_fit_final$store,test_prob_score))
lgr_final_test
View(lgr_final_test)
auc(roc(lgr_test$store,test_prob_score))
test_prob_score
test_prob_score[,1]
test_prob_score[1]
test_prob_score
write.csv(test_prob_score,"Rajesh_Khan_P2_part2.csv", row.names = F)
auc(roc(lgr_test$store,test_prob_score))
#vis_dat(ld_all)
lgr_final_test = lgr_test=ld_all %>% filter(data=='test') %>% select(-data)
View(lgr_final_test)
View(lgr_test)
View(lgr_train)
View(lgr_test)
library(dplyr)
library(visdat)
library(tidyr)
library(car)
library(stringr)
library(pROC)
setwd("C:\\Users\\Admin\\Desktop\\retail")
ld_train = read.csv("store_train.csv",stringsAsFactors = F)
ld_test  =read.csv("store_test.csv",stringsAsFactors = F)
ld_test$store=NA
ld_train$data = "train"
ld_test$data = "test"
ld_all = rbind(ld_train,ld_test)
sales_vector = c("sales0","sales1","sales2","sales3","sales4")
for(i in sales_vector){
print(sum(is.na(ld_all[,i])))
}
ld_all$sales_mean = rowMeans(subset(ld_all, select = c("sales0","sales1","sales2","sales3","sales4")), na.rm = TRUE)
ld_all = ld_all %>%
select(-sales_vector)
table(ld_all$store_Type)
CreateDummies=function(data,var,freq_cutoff=0){
t=table(data[,var])
t=t[t>freq_cutoff]
t=sort(t)
categories=names(t)[-1]
for( cat in categories){
name=paste(var,cat,sep="_")
name=gsub(" ","",name)
name=gsub("-","_",name)
name=gsub("\\?","Q",name)
name=gsub("<","LT_",name)
name=gsub("\\+","",name)
name=gsub("\\/","_",name)
name=gsub(">","GT_",name)
name=gsub("=","EQ_",name)
name=gsub(",","",name)
data[,name]=as.numeric(data[,var]==cat)
}
data[,var]=NULL
return(data)
}
ld_all = CreateDummies(ld_all,"store_Type",10)
ld_all$storecode = substr(ld_all$storecode, start = 1, stop = 5)
ld_all = CreateDummies(ld_all,"storecode",50)
ld_all$Id=NULL
ld_all$State=NULL
ld_all$countyname=NULL
ld_all$countytownname=NULL
ld_all$country=NULL
ld_all$Areaname=NULL
ld_all=CreateDummies(ld_all,"state_alpha",0)
#vis_dat(ld_all)
lgr_final_test = lgr_test=ld_all %>% filter(data=='test') %>% select(-data)
lgr_train=ld_all %>% filter(data=='train') %>% select(-data)
lgr_test=ld_all %>% filter(data=='test') %>% select (-data,-store)
set.seed(2)
s=sample(1:nrow(lgr_train),0.8*nrow(lgr_train))
lgr_train1=lgr_train[s,] ## 80% Train data
lgr_train2=lgr_train[-s,] ## 20% Train Test Data
for_vif=lm(store~.-state_alpha_GU,data = lgr_train1)
sort(vif(for_vif), decreasing = T)[1:3]
log_fit = glm(store~.-state_alpha_GU,data = lgr_train1)
log_fit = step(log_fit)
formula(log_fit)
log_fit= glm(store~ storecode_NCNTY + state_alpha_HI + state_alpha_NC,data = lgr_train1, family ='binomial')
'summary(log_fit)'
val.score=predict(log_fit,newdata = lgr_train2, type='response')
'val.score'
auc(roc(lgr_train2$store,val.score))
log_fit_final= glm(store~ storecode_NCNTY + state_alpha_HI + state_alpha_NC,data = lgr_train, family ='binomial')
summary(log_fit_final)
test_prob_score = predict(log_fit_final, newdata = lgr_test, type='response',row.names= F )
'test_prob_score'
'auc(roc(lgr_test$store,test_prob_score))'
write.csv(test_prob_score,"Rajesh_Khan_P2_part2.csv", row.names = F)
View(log_fit_final)
write.csv(test_prob_score,"Rajesh_Khan_P2_part2.csv", row.names = F)
auc(roc(lgr_train2$store,val.score))
log_fit_final= glm(store~ storecode_NCNTY + state_alpha_HI + state_alpha_NC,data = lgr_train, family ='binomial')
View(log_fit_final)
auc(roc(lgr_test$store_Type_SupermarketType3,test_prob_score))
auc(roc(lgr_test$store_Type_GroceryStore,test_prob_score))
auc(roc(lgr_test$store_Type_SupermarketType1,test_prob_score))
library(dplyr)
library(visdat)
library(tidyr)
library(car)
library(stringr)
library(pROC)
setwd("C:\\Users\\Admin\\Desktop\\retail")
ld_train = read.csv("store_train.csv",stringsAsFactors = F)
ld_test  =read.csv("store_test.csv",stringsAsFactors = F)
ld_test$store=NA
ld_train$data = "train"
ld_test$data = "test"
ld_all = rbind(ld_train,ld_test)
View(ld_train)
sales_vector = c("sales0","sales1","sales2","sales3","sales4")
for(i in sales_vector){
print(sum(is.na(ld_all[,i])))
}
ld_all$sales_mean = rowMeans(subset(ld_all, select = c("sales0","sales1","sales2","sales3","sales4")), na.rm = TRUE)
View(ld_all)
View(ld_all)
ld_all = ld_all %>%
select(-sales_vector)
CreateDummies=function(data,var,freq_cutoff=0){
t=table(data[,var])
t=t[t>freq_cutoff]
t=sort(t)
categories=names(t)[-1]
for( cat in categories){
name=paste(var,cat,sep="_")
name=gsub(" ","",name)
name=gsub("-","_",name)
name=gsub("\\?","Q",name)
name=gsub("<","LT_",name)
name=gsub("\\+","",name)
name=gsub("\\/","_",name)
name=gsub(">","GT_",name)
name=gsub("=","EQ_",name)
name=gsub(",","",name)
data[,name]=as.numeric(data[,var]==cat)
}
data[,var]=NULL
return(data)
}
ld_all = CreateDummies(ld_all,"store_Type",10)
ld_all = CreateDummies(ld_all,"storecode",50)
ld_all$Id=NULL
ld_all$State=NULL
ld_all$countyname=NULL
ld_all$countytownname=NULL
ld_all$country=NULL
ld_all$Areaname=NULL
ld_all=CreateDummies(ld_all,"state_alpha",0)
ld_train = read.csv("store_train.csv",stringsAsFactors = F)
lgr_train=ld_all %>% filter(data=='train') %>% select(-data)
lgr_test=ld_all %>% filter(data=='test') %>% select (-data,-store)
set.seed(2)
s=sample(1:nrow(lgr_train),0.8*nrow(lgr_train))
lgr_train1=lgr_train[s,] ## 80% Train data
lgr_train2=lgr_train[-s,] ## 20% Train Test Data
for_vif=lm(store~.-state_alpha_GU,data = lgr_train1)
View(for_vif)
View(for_vif)
{
library(dplyr)
library(visdat)
library(tidyr)
library(car)
library(stringr)
library(pROC)
setwd("C:\\Users\\Admin\\Desktop\\retail")
ld_train = read.csv("store_train.csv",stringsAsFactors = F)
ld_test  =read.csv("store_test.csv",stringsAsFactors = F)
ld_test$store=NA
ld_train$data = "train"
ld_test$data = "test"
ld_all = rbind(ld_train,ld_test)
sales_vector = c("sales0","sales1","sales2","sales3","sales4")
for(i in sales_vector){
print(sum(is.na(ld_all[,i])))
}
ld_all$sales_mean = rowMeans(subset(ld_all, select = c("sales0","sales1","sales2","sales3","sales4")), na.rm = TRUE)
ld_all = ld_all %>%
select(-sales_vector)
table(ld_all$store_Type)
CreateDummies=function(data,var,freq_cutoff=0){
t=table(data[,var])
t=t[t>freq_cutoff]
t=sort(t)
categories=names(t)[-1]
for( cat in categories){
name=paste(var,cat,sep="_")
name=gsub(" ","",name)
name=gsub("-","_",name)
name=gsub("\\?","Q",name)
name=gsub("<","LT_",name)
name=gsub("\\+","",name)
name=gsub("\\/","_",name)
name=gsub(">","GT_",name)
name=gsub("=","EQ_",name)
name=gsub(",","",name)
data[,name]=as.numeric(data[,var]==cat)
}
data[,var]=NULL
return(data)
}
}
#Data Preparation
{
ld_all = CreateDummies(ld_all,"store_Type",10)
ld_all$storecode = substr(ld_all$storecode, start = 1, stop = 5)
ld_all = CreateDummies(ld_all,"storecode",50)
ld_all$Id=NULL
ld_all$State=NULL
ld_all$countyname=NULL
ld_all$countytownname=NULL
ld_all$country=NULL
ld_all$Areaname=NULL
ld_all=CreateDummies(ld_all,"state_alpha",0)
}
#vis_dat(ld_all)
#separation of training data
{
lgr_final_test = lgr_test=ld_all %>% filter(data=='test') %>% select(-data)
lgr_train=ld_all %>% filter(data=='train') %>% select(-data)
lgr_test=ld_all %>% filter(data=='test') %>% select (-data,-store)
set.seed(2)
s=sample(1:nrow(lgr_train),0.8*nrow(lgr_train))
lgr_train1=lgr_train[s,] ## 80% Train data
lgr_train2=lgr_train[-s,] ## 20% Train Test Data
}
#RandomForest
{
ld.tree=randomForest(store~.,data=lgr_train1)
val.IR=predict(ld.tree, newdata = lgr_train2)
}
{
library(dplyr)
library(visdat)
library(tidyr)
library(car)
library(stringr)
library(pROC)
setwd("C:\\Users\\Admin\\Desktop\\retail")
ld_train = read.csv("store_train.csv",stringsAsFactors = F)
ld_test  =read.csv("store_test.csv",stringsAsFactors = F)
ld_test$store=NA
ld_train$data = "train"
ld_test$data = "test"
ld_all = rbind(ld_train,ld_test)
sales_vector = c("sales0","sales1","sales2","sales3","sales4")
for(i in sales_vector){
print(sum(is.na(ld_all[,i])))
}
ld_all$sales_mean = rowMeans(subset(ld_all, select = c("sales0","sales1","sales2","sales3","sales4")), na.rm = TRUE)
ld_all = ld_all %>%
select(-sales_vector)
table(ld_all$store_Type)
CreateDummies=function(data,var,freq_cutoff=0){
t=table(data[,var])
t=t[t>freq_cutoff]
t=sort(t)
categories=names(t)[-1]
for( cat in categories){
name=paste(var,cat,sep="_")
name=gsub(" ","",name)
name=gsub("-","_",name)
name=gsub("\\?","Q",name)
name=gsub("<","LT_",name)
name=gsub("\\+","",name)
name=gsub("\\/","_",name)
name=gsub(">","GT_",name)
name=gsub("=","EQ_",name)
name=gsub(",","",name)
data[,name]=as.numeric(data[,var]==cat)
}
data[,var]=NULL
return(data)
}
}
#Data Preparation
{
ld_all = CreateDummies(ld_all,"store_Type",10)
ld_all$storecode = substr(ld_all$storecode, start = 1, stop = 5)
ld_all = CreateDummies(ld_all,"storecode",50)
ld_all$Id=NULL
ld_all$State=NULL
ld_all$countyname=NULL
ld_all$countytownname=NULL
ld_all$country=NULL
ld_all$Areaname=NULL
ld_all=CreateDummies(ld_all,"state_alpha",0)
}
#vis_dat(ld_all)
#separation of training data
{
lgr_final_test = lgr_test=ld_all %>% filter(data=='test') %>% select(-data)
lgr_train=ld_all %>% filter(data=='train') %>% select(-data)
lgr_test=ld_all %>% filter(data=='test') %>% select (-data,-store)
set.seed(2)
s=sample(1:nrow(lgr_train),0.8*nrow(lgr_train))
lgr_train1=lgr_train[s,] ## 80% Train data
lgr_train2=lgr_train[-s,] ## 20% Train Test Data
}
#RandomForest
{
ld.tree=randomForest(store~.,data=lgr_train1)
val.IR=predict(ld.tree, newdata = lgr_train2)
}
rmse_val=((val.IR)-(ld_train2$Price))^2 %>% mean() %>% sqrt()
rmse_val=((val.IR)-(lgr_train2$Price))^2 %>% mean() %>% sqrt()
rmse_val
ld.tree=randomForest(store~.,data=lgr_train1)
ld.tree=lm(store~.,data=lgr_train1)
val.IR=predict(ld.tree, newdata = lgr_train2)
ld.tree=lm(store~.-state_alpha_GU,data=lgr_train1)
val.IR=predict(ld.tree, newdata = lgr_train2)
val.IR
rmse_val=((val.IR)-(lgr_train2$Price))^2 %>% mean() %>% sqrt()
rmse_val
rmse_val=((val.IR)-(lgr_train2$store))^2 %>% mean() %>% sqrt()
rmse_val
ld.tree=glm(store~.-state_alpha_GU,data=lgr_train1)
val.IR=predict(ld.tree, newdata = lgr_train2)
val.IR
rmse_val=((val.IR)-(lgr_train2$store))^2 %>% mean() %>% sqrt()
rmse_val
